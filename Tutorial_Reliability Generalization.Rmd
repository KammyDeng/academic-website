---
title: "Reliability Generalization Workshop"
author: "Jiaxin Deng"
date: "2022/7/16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

----------Table of Contents--------------------------------------------------------------------------------------------  
---------- 1. Meta-analysis in R --------------------------------------------------------------  
---------- 2. Example: Deng et al. (2019) Reliability generalization of the ICU-----------------------  
---------- Hands-on exercises: Practice with demo data-------------------------------------------------------  
---------- 3. Summary------------------------------------------------------------------------------------------  
---------- 4. Resources --------------------------------------------------------------------------------  


## 1. Meta-analysis in R
*R* programming is commonly used in the data analysis of meta-analysis and reliability generalization.  

Several commonly used R packages in the meta-analysis include `metafor`(Viechtbauer, 2010), `metaSEM` (Cheung, 2015), etc. For details, see Polanin et al. (2017). This review summarizes 63 currently available packages for meta-analysis and provides comparisons and suggestions for their use in terms of functions.

Polanin, J. R., Hennessy, E. A., & Tanner-Smith, E. E. (2017). A Review of Meta-Analysis Packages in R. *Journal of Educational and Behavioral Statistics*, *42*, 206–242. 

One of the most widely used packages for conducting meta-analysis is `metafor`, which was written and developed by Professor Wolfgang Viechtbauer of Maastricht University in the Netherlands. Compared with other packages, `metafor` covers the statistical analysis process of meta-analysis quite comprehensively, including calculating effect size, conducting moderator analysis, analyzing publication bias, and using multi-level models to deal with nested dependent variable effect size.  

Many RG studies used the`metafor`package as a tool for statistical analysis, such as:  

[1] Blázquez-Rincón, D., Durán, J. I., & Botella, J. (2022). The fear of COVID-19 scale: a reliability generalization meta-analysis. *Assessment*, *29*, 940–948.

[2] Rubio-Aparicio, M., Núñez-Núñez, R. M., Sánchez-Meca, J., López-Pina, J. A., Marín-Martínez, F., & López-López, J. A. (2020). The Padua Inventory–Washington State University Revision of obsessions and compulsions: A reliability generalization meta-analysis. *Journal of Personality Assessment*, *102*, 113–123. 

[3] Vicent, M., Rubio-Aparicio, M., Sánchez-Meca, J., & Gonzálvez, C. (2019). A reliability generalization meta-analysis of the child and adolescent perfectionism scale. *Journal of Affective Disorders*, *245*, 533–544.

[4] Piqueras, J. A., Martín-Vivar, M., Sandin, B., San Luis, C., & Pineda, D. (2017). The Revised Child Anxiety and Depression Scale: A systematic review and reliability generalization meta-analysis. *Journal of affective disorders*, *218*, 153–169.

[5] López-Pina, J. A., Sánchez-Meca, J., López-López, J. A., Marín-Martínez, F., Núñez-Núñez, R. M., Rosa-Alcázar, A.  I., ... & Ferrer-Requena, J. (2015). The Yale–Brown obsessive compulsive scale: A reliability generalization meta-analysis. *Assessment*, *22*, 619–628.

Therefore, the following example studies will demonstrate how to perform statistical analysis using the `metafor` package (Viechtbauer, 2010).  

##2. Example: Deng et al. (2019) Reliability generalization of the ICU

### Brief introduction
The following is an RG example of the Inventory of Callous-Unemotional traits (Deng et al., 2019), specifically describe how to conduct an RG study, focusing on software operations for statistical analysis.

The 24-item scale contains three subscales, Callousness, Uncaring, and Unemotional, using Likert 4 scored. Here is a brief summary of the specific process:  

#### Preparation   
##### 1. Literature search and screening  
In this study, a total of 1,125 articles were downloaded from multiple databases using multiple keywords. After applying filtering criteria, 146 articles were ultimately retained.    

##### 2. Data extraction and encoding  
(1) Effect size: the total score and its subscale Cronbach's alpha coefficient  
(2) The moderators are included as follows:  
(a) SD of age  
(b) Mean age  
(c) % of males in sample  
(d) sample size  
(e) SD of total scores  
(f) Mean of total scores  
(g) administration format  
(h) age group  
(i) sample type  
(j) language version  
(k) country  
(l) item number version  

(2) Data analysis
In this section, the total score α coefficient of the scale (24 items) and the moderators of 53 studies in this study were selected as demo data.  
+ effect size: the alpha coefficient of the total score of the scale  
+ Continuous variables: sample size, mean age and standard deviation, gender percentage, mean and standard deviation of the total score   
+ Categorical variables: age type, sample type, language, adminstration ratings    

Examples of specific encoding rules are as follows:
```{r coding1, include=FALSE,warnings = FALSE, message=FALSE}
library(readxl)#install with install.packages ("readxl").
library(openxlsx) # install.packages ("openxlsx").
options(tidyverse.quiet = TRUE)#settings tidyverse comes with packages and their version information
library (tidyverse) # install.packages ("tidyverse").
library(metafor)# install.packages ("metafor").
agetype=c("Infants and young children","Children","Adolescents","Adults")
sampletype=c("community","offender")
language=c("english","non-english")
ratingformat=c("self-report","parent-report","teacher-report")

criteria <- tibble(variable = NA %>% as.character(), 
                    c1 = NA %>% as.character(), 
                    c2 = NA %>% as.character(), 
                    c3 = NA %>% as.character(), 
                    c4 = NA %>% as.character())
criteria [1:4, 1] <- c ("agetype","sampletype","language","ratingformat")
criteria [1, 2:5] <- t(agetype)
criteria [2, 2:3] <- t(sampletype)
criteria [3, 2:3] <- t(language)
criteria [4, 2:4] <- t(ratingformat)
criteria
```

```{r coding2, include=TRUE,warnings = FALSE, message=FALSE}
criteria %>% knitr::kable()
```

Next, I will demonstrate how to conduct the analysis using demo data.  

### 2.1.1 Installation and load packages
First, install and run the package. The code is displayed as follows:  

```{r load, warnings = FALSE, message=FALSE}
library(readxl)
library(openxlsx) 
options(tidyverse.quiet = TRUE)
library (tidyverse) 
library(metafor)
```

### 2.1.2 Data reading and import
To use the example shown, you first need to import the data. Since the data file is in Excel format, you can use the `readxl` package to read and import the data. Use this code with the appropriate file path to import the data.  

```{r import, warnings = FALSE}
data<-read_excel("example_data.xlsx") #demo data in the current working directory
head(data,10)#10 rows
#data consists of 3 parts:
#(1) Effect size: alpha
#(2) Continuous regulation variables
#(3) Categorical moderators

#read_excel("path/to/data_file.xlsx") #specific path
```

### 2.2 Heterogeneity testing
To examine heterogeneity in the effect size, the variability of the α coefficients was mainly tested using the `rma()` function.  

Before testing for heterogeneity, the effect size needs to be calculated, which is done mainly by the `escalc()` function.

The `escalc()` function include the following parameters:  
(1) measure is used to convert Cronbach's α coefficient or use the original value;  
(2) ai is the observed Cronbach's α coefficient;  
(3) ni is the sample size and mi is the number of items;  
(4) dat is the dataset.  

For example, to use the form without transformation, set measure to "ARAW" with the following code:

```{r esc0, warnings = FALSE, message=FALSE}
#raw alpha
total_es_raw<-escalc(measure = "ARAW", ai=alpha_total, ni=size, mi=mi, dat=data)
total_es_raw[1:10,]#yi--effect size,vi--sampling variance; the first 10 rows
```

If use the Bonett (2002) formula for conversion, set measure to "ABT" with the following code: 
```{r esc1, warnings = FALSE, message=FALSE}
#use Bonett's (2002) formula to convert and calculate the weighted average alpha coefficient
total_es <- escalc("ABT",-ln(1-ai), ai=alpha_total, ni=size, mi=mi, dat=data)
total_es[1:10,] #yi--effect size, vi--sampling variance; Look at the first 10 rows
```

After calculating the effect size, the `rma()` function is used for heterogeneity testing.  

```{r het1, warnings = FALSE, message=FALSE}
#heterogeneity
het1<-rma(total_es, yi, vi)
het1
pred1=predict(het1, transf=transf.iabt)#back-transformation to alpha
pred1
```

In addition, you can calculate the effect size and heterogeneity tests directly with `rma()` in one step, as shown below:

```{r het2, warnings = FALSE, message=FALSE}
het2<-rma(measure="ABT", ai=alpha_total, ni=size, mi=mi, dat=data)#default REML
het2
pred2=predict(het2, transf=transf.iabt)##back-transformation to alpha
pred2
```

The results from comparing HET1 and HET2 are the same, indicating that either of them can be used.  
Furthermore, you can choose different estimation methods by setting the `method` parameter. The Restricted Maximum Likelihood method (REML) is generally used by default. If you want to use other estimation methods, you can set `method="ML"` to use maximum likelihood estimation.  

```{r het3, warnings = FALSE, message=FALSE}
#method=ML
het3<-rma(total_es, yi, vi, method="ML")
het3
pred3=predict(het3, transf=transf.iabt)#back-transformation to alpha
pred3
```

Interpretation of the results:

(1) The figure above shows the results of estimation using a random-effects model, with 53 effect sizes and maximum likelihood estimation.

(2) Four indicators are provided for evaluating the heterogeneity: τ, τ2, H2, and I2. Among them, I2 is about 92%, indicating a high level of heterogeneity according to the criteria.

(3) The Q value is 576.2518 with *p*<.0001, indicating that the heterogeneity test was significant.  

(4) Based on the results of the different estimation methods, heterogeneity exists. Therefore, it is necessary to further explore the factors contributing to the heterogeneity of these α coefficients.  
In addition to directly extracting the results, you can also use code to organize the results in *R*, which is more convenient and fast.  
---- this part is mainly based on R if and loop code, and does not involve reliability generalization analysis, so it will not be further expanded here. ----  

The following table shows the results of the heterogeneity analysis.  

```{r het_res,include=FALSE, warnings = FALSE, message=FALSE}
Q.value <- "0" #Q.value
if (het3[["QEp"]] > 0.05) {
    Q.value <- paste(round (het3[["QE"]], 3))
  } else if (0.01 < het3[["QEp"]] & het3[["QEp"]] < 0.05) {
    Q.value <- paste0(round (het3[["QE"]], 3), "*")
  } else if (0.001 < het3[["QEp"]] & het3[["QEp"]] < 0.01) {
    Q.value <- paste0(round (het3[["QE"]], 3), "**")
  } else if (het3[["QEp"]] < 0.001) {
    Q.value <- paste0(round (het3[["QE"]], 3), "***")
  }

het3_res <- tibble (
  k = het3[["k"]],
  mean_alpha = round (pred3[["pred"]], 2),
  CI.LB = round (pred3[["ci.lb"]], 2),
  CI.UB = round (pred3[["ci.ub"]], 2),
  #tranfs_mean_alpha = round (het3[["b"]], 2),
  #tranfs_CI.LB = round (het3[["ci.lb"]], 2),
  #tranfs_CI.UB = round (het3[["ci.ub"]], 2),
  Tau2 = round (het3[["tau2"]], 3),
  Q = Q.value,
  I2_precent = round (het3[["I2"]], 2)
)

het3_res %>% knitr::kable()
```

```{r print het3_res,include=TRUE, warnings = FALSE, message=FALSE}
het3_res %>% knitr::kable()
```

### 2.3 Forest plot
Use the `forest.rma()` function to build a forest plot to visualize the distribution of effect size. 
```{r forest0, warnings = FALSE, message=FALSE,fig.width=8,fig.height=12}
forest.rma(het3)#transformed alpha
```

Interpretation of the results:
The figure displays the name of each study in the first column, the distribution of effect size in the middle, and the effect size corresponding to each study and their confidence interval on the right.  
You can also adjust the parameters as needed. Here are some options:  
(1) Set `annotate=TRUE` to add labels to the figure. This is generally the default setting.  
(2) Use `transf` to convert the effect size.  
(3) Use `showweights` to set the weights for presenting the impact of each studies on the overall effect size.  
(4) Use `header` to determine whether to include a header in the figure.  

The specific code is as follows:  

```{r forest1, warnings = FALSE, message=FALSE,fig.width=8,fig.height=12}
forest.rma(het3,annotate=TRUE,transf=transf.iabt,header = TRUE,showweights=TRUE)#backtransformed alpha
```

Interpretation of the results:  
(1) A mean effect of 0.81 was estimated using a random-effects model.  
(2) The analysis yielded a mean α coefficient of 0.81, indicating good internal consistency.  
To save the result graph as a pdf, use the following code:  

```{r forest2, warnings = FALSE, message=FALSE,fig.width=8,fig.height=12}
pdf("forestplot.pdf",width=10, height=20)
forest.rma(het3,annotate=TRUE,transf=transf.iabt,header = TRUE,showweights=TRUE)#backtransformed alpha
dev.off()
```

### 2.4 Moderator analysis
Moderator analysis is mainly done by setting the `mods` parameter in `rma()` in order to analyze the effect of the included moderator on heterogeneity results.  
The analysis parameter setting is typically used: `rma (total_es, yi, vi, mods = ~ moderator)`.  

#### 2.4.1 Example of a continuous variable
Using the standard deviation of the total score of the scale as an example, the code to include a single moderator for analysis is as follows:

```{r moderator1, warnings = FALSE, message=FALSE}
res_tot_totalSD<-rma(total_es, yi, vi, mods=~totalSD,method="ML")
res_tot_totalSD
```

```{r moderator2, warnings = FALSE, message=FALSE}
res_tot_totalSD<-rma(measure="ABT", ai=alpha_total, ni=size, mi=mi, mods=~totalSD,dat=  data,method="ML") #same results, the difference is that the variables in the dataset are used directly
res_tot_totalSD
```

Interpretation of the results:  
(1) The moderator analysis used the the maximum likelihood estimation based on the mixed-effects model, as shown in the first row.  
(2) The effect of the moderators are also reported, with *p*<.0001, indicating that the standard deviation of the total score of the scale has a moderating effect on the effect size.  

In addition to directly extracting the results after analyzing each variable, you can also use code in R and organize the results, which is convenient and fast.

----- This section mainly involves R if and loop code and does not involve reliability generalization analysis. Therefore, it will not be further expanded here. ----

The following table shows the results of the moderator analysis of continuous variables included.

```{r reg_res, include=FALSE,warnings = FALSE, message=FALSE}
R2 <- array (0, 1)
QE <- array (0, 1)
p.QE <- array (0, 1)
k <- array (0, 1)
b <- array (0, 1)
t <- array (0, 1)
p.t <- array (0, 1)
name <- array ("0", 1)
QE.list <- array (" ", 5)

for (A in 6:11) {
  #  6 caterogical variables  in columns 6 to 11 in the dataset
  tmp_con <- rma (total_es, yi, vi, mods = ~ total_es[[A]], method="ML")
  R2[A - 5] <- round (tmp_con [["R2"]], 2)
  QE[A - 5] <- round (tmp_con [["QE"]], 3)
  p.QE[A - 5] <- tmp_con [["QEp"]]
  k[A - 5] <- tmp_con[["k"]]
  b[A - 5] <- round (tmp_con[["beta"]][2], 3)
  t[A - 5] <- round (tmp_con[["zval"]][2], 3)
  p.t[A - 5] <- round (tmp_con[["pval"]][2], 3)
  name[A - 5] <- names (total_es)[A]
  if (p.QE[A - 5] > 0.05) {
    QE.list[A - 5] <- paste(QE[A - 5])
  }
  else if (0.01 < p.QE[A - 5] & p.QE[A - 5] < 0.05) {
    QE.list[A - 5] <- paste(QE[A - 5], "*")
  }
  else if (0.001 < p.QE[A - 5] & p.QE[A - 5] < 0.01) {
    QE.list[A - 5] <- paste(QE[A - 5], "**")
  }
  else if (p.QE[A - 5] < 0.001) {
    QE.list[A - 5] <- paste(QE[A - 5], "***")
    }
}

# A - 5 here is similar to A - 1 in Meta-Anova.

reg_res <- tibble (
  variable = name,
  k = k,
  b = b,
  t = t,
  sig.t = p.t,
  R2_percentage = R2,
  QE = QE.list)

#remove (R2, QE, p.QE, k, b, t, 
#        p.t, name, QE.list, tmp_con, A)
reg_res %>% knitr::kable()

```

```{r print reg_res,include=TRUE, warnings = FALSE, message=FALSE}
reg_res %>% knitr::kable()
#b=beta
#t=significance test of moderator regression coefficient--zval
#sig.t=p-value
#R2% explain
```


#### 2.4.2 Examples of categorical variables
To present an analysis of categorical variables in moderator analysis using the example of administration ratings, the following code is shown as follows:

###### (1) Subgroup Analysis
```{r sub1, warnings = FALSE, message=FALSE}
sub_1=rma(total_es, yi, vi, subset = (total_es$ratingformat == 1))
predict(sub_1, transf=transf.iabt) #backtransformed alpha
```

```{r sub2, warnings = FALSE, message=FALSE}
sub_2=rma (total_es, yi, vi, subset = (total_es$ratingformat == 2))
predict(sub_2, transf=transf.iabt)#backtransformed alpha
```

```{r sub3, warnings = FALSE, message=FALSE}
sub_3=rma (total_es, yi, vi, subset = (total_es$ratingformat == 3))
predict(sub_3, transf=transf.iabt) #backtransformed alpha
```

The table below shows the results of the subgroup analysis.  

```{r mod_res, include=FALSE,warnings = FALSE, message=FALSE}
subgroup <- 0
N <- 1
for (A in 2:5) { 
  # 4 caterogical variables in columns 2 to 5 in the dataset
  subgroup <- subgroup + length (unique (total_es[[A]]))
}

sub_alphas <- array (0, subgroup)
k <- array (0, subgroup)
lb <- array (0, subgroup)
ub <- array (0, subgroup)


for (S in 2:5) {
  for (K in 1:length (unique (total_es[[S]]))) {
    tmp_sub <- rma(total_es, yi, vi, subset = (total_es[[S]] == K))
    pred=predict(tmp_sub, transf=transf.iabt)
    alpha <- pred[["pred"]]
    num <- tmp_sub[["k"]]
    Lb <- pred[["ci.lb"]]
    Ub <- pred[["ci.ub"]]
    sub_alphas[N] <- round (alpha, 2)
    k[N] <- num
    lb[N] <- round (Lb, 2)
    ub[N] <- round (Ub, 2)
    N <- N + 1
  }
}

ci <- array (" ", subgroup)
for (V in 1:subgroup) 
  {ci[V] <- paste ("[", lb[V], ", ", ub[V], "]")}

mod_res <- tibble (
  group = c (agetype, sampletype, language,ratingformat),
  k = k,
  alpha = round (sub_alphas, 2),
  ci_95 = ci)

#remove (A, S, K, N, V, tmp, sub_alphas, k, lb, ub, ci) 

mod_res %>% knitr::kable()
```

```{r print mod_res,include=TRUE, warnings = FALSE, message=FALSE}
mod_res %>% knitr::kable()
```


##### (2) Meta-Anova
```{r metaanova, warnings = FALSE, message=FALSE}
res_tot_adf<-rma(total_es, yi, vi,mods=~ratingformat,method="ML")
res_tot_adf
```

The results of the effect of the moderators were reported,*p*<.05, indicating that the effect was on the adminstration ratings.  

The following table is the result of the moderator analysis of categorical variables.  

```{r anv_res,include=FALSE, warnings = FALSE, message=FALSE}
R2 <- array (0, 1)
QB <- array (0, 1)
p <- array (0, 1)
k <- array (0, 1)
name <- array ("0", 1)

for (A in 2:5) {
  tmp_cat <- rma (total_es, yi, vi, mods = ~ total_es[[A]],method="ML")
  R2[A - 1] <- round (tmp_cat [["R2"]], 2) 
  QB[A - 1] <- round (tmp_cat [["QM"]], 3)
  p[A - 1] <- round (tmp_cat [["QMp"]], 3)
  k[A - 1] <- tmp_cat[["k"]]
  name[A - 1] <- criteria$variable[A - 1]
}

anv_res <- tibble (
  variable = name,
  k = k,
  R2_percentage = R2,
  QB = QB,
  sig = p)

#remove (R2, QB, p, k, name, tmp_cat, A) 
anv_res %>% knitr::kable()
#R2% interpretation rate
#QB--QM
#sig: p-value of significant difference between QB groups
```

```{r print anv_res,include=TRUE, warnings = FALSE, message=FALSE}
anv_res %>% knitr::kable()
```

#### 2.4.3 Examples of exploratory models
Select the above variables with moderating effect or high explanatory percentage into the model for analysis, and the specific code is as follows:

```{r multi, warnings = FALSE, message=FALSE}
#full model
res_multi<-rma(total_es, yi, vi, mods=~ageM+totalM+totalSD+ratingformat,method="ML")
res_multi#R2=36.79%
```


### 2.5 Publication bias
#### 2.5.1 Funnel plot
Funnel plot is a common analytical technique for sensitivity analysis, which can visually detect whether the current study is biased.  
The specific code is as follows:

```{r funnel, warnings = FALSE, message=FALSE,fig.width=8,fig.height=8}
funplot1=funnel(het3,atransf=transf.iabt) #funnel plot
funplot2=funnel(het3,atransf=transf.iabt,label = TRUE)#studyID tag
```

Interpretation of the results:  
As can be seen from the figure, scatter points are mainly distributed at the top of the funnel and concentrated in the middle, indicating no or low probability of publication bias.  

In addition, the Trim-and-fill method was used to analyze for publication bias as follows:

```{r tf, warnings = FALSE, message=FALSE,fig.width=8,fig.height=8}
tf=trimfill(het3,estimator = "R0") #Trim-and-fill 
tf
```

Interpretation of the results:  
Estimates using the Trim-and-fill method found that the number of missing studies on the right side of the estimate was 0, indicating no bias.  

In addition, the correlation between effect size and sampling variance can be further analyzed. If the correlation is high, it indicates that the funnel graph is asymmetric, that is, there is bias.  

```{r ranktest, warnings = FALSE, message=FALSE}
ranktest (total_es$yi, total_es$vi,exact=FALSE) #correlation coefficient 0.05 - Low correlation - funnel plot is symmetric - no or low risk of bias. 
```


#### 2.5.2 Fail-safe N
Use the `fsn()` function to calculate the Fail-safe N with the following code:

```{r fsn1, warnings = FALSE, message=FALSE}
fail_safe=fsn(yi, vi, data=total_es,type="Rosenthal")
fail_safe
5*nrow(data)+10# was compared to the calculated results of 5*k+10 (k is the number of included analyses).
```

Interpretation of the results:
(1) Line 1 indicates that the Fail-safe N was calculated using the "Rosenthal" method.  
(2) The Fail-safe N is compared to the calculated result of 5*k + 10 (where k is the number of included analyses). If the Fail-safe N is less than the calculated value, then there is a risk of publication bias.  
(3) The results show the Fail-safe N of 359983, which is much higher than the number included in the analysis, indicating no publication bias.  

In general, Fail-safe N are generally collated with heterogeneity results, as follows:

```{r fsn2, include=FALSE, warnings = FALSE, message=FALSE}
if (fail_safe[["pval"]] < fail_safe[["alpha"]]) {
  het3_res <- het3_res %>% mutate (FSN = paste0 (fail_safe[["fsnum"]], "***"))
} else 
  {het3_res <- het3_res %>% mutate (FSN = paste (fail_safe[["fsnum"]]))}
het3_res %>% knitr::kable()
```

```{r fsn3, include=TRUE, warnings = FALSE, message=FALSE}
het3_res %>% knitr::kable()
```

#### 2.5.3 Calculate the Egger's regression test
Use the `regtest()` function for the Egger's regression test as follows:

```{r egger, warnings = FALSE, message=FALSE}
regtest(het3, model="lm")### classical Egger test
```

Interpretation of the results:
From the results, the Egger regression coefficient intercept was not significant, indicating that there was no bias or the possibility of bias was low.  

#### 2.5.4 Summary
In summary, the results of multiple analyses, including funnel plot, Trim-and-fill method, Rosenthal Fail-safe N, and Egger's regression test, indicate a low risk of bias or the absence of publication bias in this study.

```{r bias1,include=FALSE, warnings = FALSE, message=FALSE}
m1=("symmetrical")
m2=("Fail-safe N: 359983 > 5*53+10=275")
m3=("t = 0.5984, df = 51, p = 0.5522")
bias <- tibble(method = NA %>% as.character(), 
                    results = NA %>% as.character())
bias [1:3, 1] <- c("funnelplot", "fsn", "egger")
bias [1:3, 2] <- c(m1,m2,m3)
```

```{r bias2,include=TRUE, warnings = FALSE, message=FALSE}
bias %>% knitr::kable()
```


#### 2.6 Export the results
After all the analysis is completed, use the `write()` function to export the results for use in a paper or analysis report.  

```{r resultexp, warnings = FALSE, message=FALSE}
#write.xlsx (het3_res, file = "heterogeneity test results.xlsx")
#write.xlsx (reg_res, file = "continuous moderator results.xlsx")
#write.xlsx (anv_res, file = "categorical moderator results.xlsx")
```

### Practice
Try using the built-in data `dat.bonett2010` to complete a full analysis process. The code for importing the data is provided below:

```{r dat.bonett2010, warnings = FALSE, message=FALSE}
dat <- dat.bonett2010
#description: Results from 9 studies on the reliability of the Center for Epidemiologic Studies Depression (CES-D) Scale administered to children providing care to an elderly parent.
```

## 3. Summary
First, the statistical analysis process of reliability generalization is described using`metafor`with examples, including effect size calculation, heterogeneity testing, moderation analysis, and publication bias. 

![Overview of the functions of metafor (from the official website of metafor-project)](https://www.metafor-project.org/lib/exe/fetch.php/docs:diagram.png)

Secondly, the analytical strategy can be adjusted according to the purpose and aims of the research.  

> Take-away messages

1. As a meta-analysis technique that uses the reliability coefficient as the effect size, reliability generalization has both the common and specificity of meta-analysis.
    + Find out if there is a "Reliability Induction" issue.
    + Comprehensively evaluate whether a tool is stable and reliable.

2. `metafor`provides more options for the implementation of statistical analysis of reliabilit generalization.   
    + Choose the appropriate analysis method according to the aim.

***
## 4. Resources
### 4.1 CRAN documentation
Since the developer will update the R package, the code need to be used based on the manual if any updates.  

```{r help, warnings = FALSE, message=FALSE}
help(metafor) #manual
? metaphor
? escalc()
#escalc# Take escalc() as an example to look at the source code to understand the underlying logic
```

```{r paper, include=FALSE, warnings = FALSE, message=FALSE}
#vignette("metafor")#see Viechtbauer (2010)
```

### 4.2 `metafor`official website
Here are two useful websites that provide a lot of resources.  
[metafor@github](https://wviechtb.github.io/metafor/index.html)  
[Metafor-Project website] (https://www.metafor-project.org/doku.php).

### 4.3 Reference books
Harrer, M., Cuijpers, P., Furukawa, T. A., & Ebert, D. D. (2021). *Doing meta-analysis with R: A hands-on guide*. Chapman and Hall/CRC.

Polanin, J. R., Hennessy, E. A., & Tanner-Smith, E. E. (2017). A Review of Meta-Analysis Packages in R. *Journal of Educational and Behavioral Statistics*, *42*, 206–242. 

Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. *Journal of Statistical Software*, *36*, 1–48.
